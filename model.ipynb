{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\"\"\"\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\"\"\"\n",
    "\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Flatten, Input\n",
    "from keras.layers import Conv2D, Activation, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.resnet50 import preprocess_input, ResNet50\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from tensorflow.keras import callbacks\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 480 # The default size for ResNet is 224 but resize to .5 to save memory size\n",
    "H = 480 # The default size for ResNet is 224 but resize to .5 to save memory size\n",
    "label_to_class = {\n",
    "    '025866':0,\n",
    "    '006271':1,\n",
    "    '013382':2,\n",
    "    '046613':3,\n",
    "    '029090':4,\n",
    "    '022105':5,\n",
    "    '046118':6,\n",
    "    '037441':7,\n",
    "    '011701':8,\n",
    "    '006263':9,\n",
    "    '028452':10,\n",
    "    '018620':11,\n",
    "    '045267':12,\n",
    "    '040011':13,\n",
    "    '055232':14,\n",
    "    '004085':15,\n",
    "    '027940':16,\n",
    "    '044710':17,\n",
    "    '004928':18,\n",
    "    '039863':19,\n",
    "    '040699':20,\n",
    "    '038575':21,\n",
    "    '021882':22,\n",
    "    '009102':23,\n",
    "    '047418':24,\n",
    "    '015392':25\n",
    "}\n",
    "class_to_label = {v: k for k, v in label_to_class.items()}\n",
    "n_classes = len(label_to_class)\n",
    "\n",
    "def get_images(dir_name, label_to_class):\n",
    "    \"\"\"read images / labels from directory\"\"\"\n",
    "    \n",
    "    Images = []\n",
    "    Classes = []\n",
    "    \n",
    "    for label_name in os.listdir(dir_name):\n",
    "        cls = label_to_class[label_name]\n",
    "        \n",
    "        for img_name in os.listdir('/'.join([dir_name, label_name])):\n",
    "            img = load_img('/'.join([dir_name, label_name, img_name]), target_size=(W, H))\n",
    "            img = img_to_array(img)\n",
    "            \n",
    "            Images.append(img)\n",
    "            Classes.append(cls)\n",
    "            \n",
    "    Images = np.array(Images, dtype=np.float32)\n",
    "    Classes = np.array(Classes, dtype=np.float32)\n",
    "    Images, Classes = shuffle(Images, Classes, random_state=0)\n",
    "    \n",
    "    return Images, Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get images / labels\n",
    "\n",
    "Images, Classes = get_images(dir_name='d:/7.medicine_project/dataset/train',label_to_class=label_to_class)\n",
    "Images.shape, Classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize some images / labels\n",
    "\n",
    "n_total_images = Images.shape[0]\n",
    "\n",
    "for target_cls in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "                  20, 21, 22, 23, 24, 25]:\n",
    "    \n",
    "    indices = np.where(Classes == target_cls)[0] # get target class indices on Images / Classes\n",
    "    n_target_cls = indices.shape[0]\n",
    "    label = class_to_label[target_cls]\n",
    "    print(label, n_target_cls, n_target_cls/n_total_images)\n",
    "\n",
    "    n_cols = 10 # # of sample plot\n",
    "    fig, axs = plt.subplots(ncols=n_cols, figsize=(25, 3))\n",
    "\n",
    "    for i in range(n_cols):\n",
    "\n",
    "        axs[i].imshow(np.uint8(Images[indices[i]]))\n",
    "        axs[i].axis('off')\n",
    "        axs[i].set_title(label)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split train / test\n",
    "\n",
    "indices_train, indices_test = train_test_split(list(range(Images.shape[0])), train_size=0.9, test_size=0.1, shuffle=True)\n",
    "\n",
    "x_train = Images[indices_train]\n",
    "y_train = Classes[indices_train]\n",
    "x_test = Images[indices_test]\n",
    "y_test = Classes[indices_test]\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to one-hot\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to image data generator\n",
    "\n",
    "datagen_train = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input, # image preprocessing function\n",
    "    rotation_range=30,                       # randomly rotate images in the range\n",
    "    zoom_range=0.1,                          # Randomly zoom image\n",
    "    width_shift_range=0.1,                   # randomly shift images horizontally\n",
    "    height_shift_range=0.1,                  # randomly shift images vertically\n",
    "    horizontal_flip=True,                    # randomly flip images horizontally\n",
    "    vertical_flip=False,                     # randomly flip images vertically\n",
    ")\n",
    "datagen_test = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input, # image preprocessing function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet\n",
    "input_tensor = Input(shape=(W, H, 3)) # To change input shape\n",
    "resnet50 = ResNet50(\n",
    "    include_top=False,                # To change output shape\n",
    "    weights='imagenet',               # Use pre-trained model\n",
    "    input_tensor=input_tensor,        # Change input shape for this task\n",
    ")\n",
    "\n",
    "# fc layer\n",
    "top_model = Sequential()\n",
    "top_model.add(GlobalAveragePooling2D())               # Add GAP for cam\n",
    "top_model.add(Dense(n_classes, activation='softmax')) # Change output shape for this task\n",
    "\n",
    "# model\n",
    "model = Model(input=resnet50.input, output=top_model(resnet50.output))\n",
    "\n",
    "# frozen weights\n",
    "for layer in model.layers[:-10]:\n",
    "    layer.trainable = False or isinstance(layer, BatchNormalization) # If Batch Normalization layer, it should be trainable\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#超過5次沒進步就停止\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "\n",
    "model_path = 'd:/7.medicine_project/test_resnet50.h5'  # 模型儲存的位置\n",
    "\n",
    "\n",
    "# 建立 Checkpoint\n",
    "checkpoint = \\\n",
    "    callbacks.ModelCheckpoint(model_path,\n",
    "                              verbose=1,\n",
    "                              monitor='val_accuracy',  # 儲存模型的指標\n",
    "                              save_best_only=True,  # 是否只儲存最好的\n",
    "                              mode='max')           # 與指標搭配模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## finetuning\n",
    "\n",
    "history = model.fit_generator(\n",
    "    datagen_train.flow(x_train, y_train, batch_size=6),\n",
    "    epochs=10,\n",
    "    validation_data=datagen_test.flow(x_test, y_test, batch_size=6),\n",
    "    callbacks=[checkpoint, early_stopping_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot confusion matrix\n",
    "\n",
    "x = preprocess_input(copy.deepcopy(x_test))\n",
    "y_preds = model.predict(x)\n",
    "y_preds = np.argmax(y_preds, axis=1)\n",
    "y_trues = np.argmax(y_test, axis=1)\n",
    "cm = confusion_matrix(y_trues, y_preds)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar_kws={'shrink': .3}, linewidths=.1, ax=ax)\n",
    "\n",
    "ax.set(\n",
    "    xticklabels=list(label_to_class.keys()),\n",
    "    yticklabels=list(label_to_class.keys()),\n",
    "    title='confusion matrix',\n",
    "    ylabel='True label',\n",
    "    xlabel='Predicted label'\n",
    ")\n",
    "params = dict(rotation=45, ha='center', rotation_mode='anchor')\n",
    "plt.setp(ax.get_yticklabels(), **params)\n",
    "plt.setp(ax.get_xticklabels(), **params)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def superimpose(img, cam):\n",
    "    \"\"\"superimpose original image and cam heatmap\"\"\"\n",
    "    \n",
    "    heatmap = cv2.resize(cam, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    superimposed_img = heatmap * .5 + img * .5\n",
    "    superimposed_img = np.minimum(superimposed_img, 255.0).astype(np.uint8)  # scale 0 to 255  \n",
    "    superimposed_img = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return img, heatmap, superimposed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot(model, cam_func, img, cls_true):\n",
    "    \"\"\"plot original image, heatmap from cam and superimpose image\"\"\"\n",
    "    \n",
    "    # for cam\n",
    "    x = np.expand_dims(img, axis=0)\n",
    "    x = preprocess_input(copy.deepcopy(x))\n",
    "\n",
    "    # for superimpose\n",
    "    img = np.uint8(img)\n",
    "\n",
    "    # cam / superimpose\n",
    "    cls_pred, cam = cam_func(model=model, x=x, layer_name=model.layers[-2].name)\n",
    "    img, heatmap, superimposed_img = superimpose(img, cam)\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=3, figsize=(9, 4))\n",
    "\n",
    "    axs[0].imshow(img)\n",
    "    axs[0].set_title('original image')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(heatmap)\n",
    "    axs[1].set_title('heatmap')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    axs[2].imshow(superimposed_img)\n",
    "    axs[2].set_title('superimposed image')\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    plt.suptitle('True label: ' + class_to_label[cls_true] + ' / Predicted label : ' + class_to_label[cls_pred])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grad-CAM function\n",
    "\n",
    "def grad_cam(model, x, layer_name):\n",
    "    \"\"\"Grad-CAM function\"\"\"\n",
    "    \n",
    "    cls = np.argmax(model.predict(x))\n",
    "    \n",
    "    y_c = model.output[0, cls]\n",
    "    conv_output = model.get_layer(layer_name).output\n",
    "    grads = K.gradients(y_c, conv_output)[0]\n",
    "\n",
    "    # Get outputs and grads\n",
    "    gradient_function = K.function([model.input], [conv_output, grads])\n",
    "    output, grads_val = gradient_function([x])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "    \n",
    "    weights = np.mean(grads_val, axis=(0, 1)) # Passing through GlobalAveragePooling\n",
    "\n",
    "    cam = np.dot(output, weights) # multiply\n",
    "    cam = np.maximum(cam, 0)      # Passing through ReLU\n",
    "    cam /= np.max(cam)            # scale 0 to 1.0\n",
    "\n",
    "    return cls, cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grad-CAM++ function\n",
    "\n",
    "def grad_cam_plus_plus(model, x, layer_name):\n",
    "    \"\"\"Grad-CAM++ function\"\"\"\n",
    "    \n",
    "    cls = np.argmax(model.predict(x))\n",
    "    y_c = model.output[0, cls]\n",
    "    conv_output = model.get_layer(layer_name).output\n",
    "    grads = K.gradients(y_c, conv_output)[0]\n",
    "\n",
    "    first = K.exp(y_c) * grads\n",
    "    second = K.exp(y_c) * grads * grads\n",
    "    third = K.exp(y_c) * grads * grads * grads\n",
    "\n",
    "    gradient_function = K.function([model.input], [y_c, first, second, third, conv_output, grads])\n",
    "    y_c, conv_first_grad, conv_second_grad, conv_third_grad, conv_output, grads_val = gradient_function([x])\n",
    "    global_sum = np.sum(conv_output[0].reshape((-1,conv_first_grad[0].shape[2])), axis=0)\n",
    "\n",
    "    alpha_num = conv_second_grad[0]\n",
    "    alpha_denom = conv_second_grad[0] * 2.0 + conv_third_grad[0] * global_sum.reshape((1, 1, conv_first_grad[0].shape[2]))\n",
    "    alpha_denom = np.where(alpha_denom != 0.0, alpha_denom, np.ones(alpha_denom.shape))\n",
    "    alphas = alpha_num / alpha_denom # 0\n",
    "\n",
    "\n",
    "    weights = np.maximum(conv_first_grad[0], 0.0)\n",
    "    alpha_normalization_constant = np.sum(np.sum(alphas, axis=0), axis=0) # 0\n",
    "    alphas /= alpha_normalization_constant.reshape((1, 1, conv_first_grad[0].shape[2])) # NAN\n",
    "    deep_linearization_weights = np.sum((weights * alphas).reshape((-1, conv_first_grad[0].shape[2])), axis=0)\n",
    "\n",
    "    cam = np.sum(deep_linearization_weights * conv_output[0], axis=2)\n",
    "    cam = np.maximum(cam, 0) # Passing through ReLU\n",
    "    cam /= np.max(cam)       # scale 0 to 1.0  \n",
    "\n",
    "    return cls, cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Score-CAM function\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"softmax\"\"\"\n",
    "    \n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "\n",
    "def score_cam(model, x, layer_name, max_N=-1):\n",
    "    \"\"\"Score-CAM function\"\"\"\n",
    "\n",
    "    cls = np.argmax(model.predict(x))\n",
    "    act_map_array = Model(inputs=model.input, outputs=model.get_layer(layer_name).output).predict(x)\n",
    "    \n",
    "    # extract effective maps\n",
    "    if max_N != -1:\n",
    "        act_map_std_list = [np.std(act_map_array[0, :, :, k]) for k in range(act_map_array.shape[3])]\n",
    "        unsorted_max_indices = np.argpartition(-np.array(act_map_std_list), max_N)[:max_N]\n",
    "        max_N_indices = unsorted_max_indices[np.argsort(-np.array(act_map_std_list)[unsorted_max_indices])]\n",
    "        act_map_array = act_map_array[:, :, :, max_N_indices]\n",
    "\n",
    "    input_shape = model.layers[0].output_shape[1:]  # get input shape\n",
    "    \n",
    "    # 1. upsampled to original input size\n",
    "    act_map_resized_list = [cv2.resize(act_map_array[0,:,:,k], input_shape[:2], interpolation=cv2.INTER_LINEAR) for k in range(act_map_array.shape[3])]\n",
    "    \n",
    "    # 2. normalize the raw activation value in each activation map into [0, 1]\n",
    "    act_map_normalized_list = []\n",
    "    for act_map_resized in act_map_resized_list:\n",
    "        if np.max(act_map_resized) - np.min(act_map_resized) != 0:\n",
    "            act_map_normalized = act_map_resized / (np.max(act_map_resized) - np.min(act_map_resized))\n",
    "        else:\n",
    "            act_map_normalized = act_map_resized\n",
    "        act_map_normalized_list.append(act_map_normalized)\n",
    "        \n",
    "    # 3. project highlighted area in the activation map to original input space by multiplying the normalized activation map\n",
    "    masked_input_list = []\n",
    "    for act_map_normalized in act_map_normalized_list:\n",
    "        masked_input = np.copy(x)\n",
    "        for k in range(3):\n",
    "            masked_input[0, :, :, k] *= act_map_normalized\n",
    "        masked_input_list.append(masked_input)\n",
    "    masked_input_array = np.concatenate(masked_input_list, axis=0)\n",
    "    \n",
    "    # 4. feed masked inputs into CNN model and softmax\n",
    "    pred_from_masked_input_array = softmax(model.predict(masked_input_array))\n",
    "    \n",
    "    # 5. define weight as the score of target class\n",
    "    weights = pred_from_masked_input_array[:, cls]\n",
    "    \n",
    "    # 6. get final class discriminative localization map as linear weighted combination of all activation maps\n",
    "    cam = np.dot(act_map_array[0, :, :, :], weights)\n",
    "    cam = np.maximum(0, cam) # Passing through ReLU\n",
    "    cam /= np.max(cam) # scale 0 to 1.0\n",
    "    \n",
    "    return cls, cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare Grad-CAM / Grad-CAM++ / Score-CAM\n",
    "\n",
    "def _compare(model, layer_name, target_cls):\n",
    "    \"\"\"compare Grad-CAM / Grad-CAM++ / Score-CAM on target class images\"\"\"\n",
    "    \n",
    "    indices = np.where(Classes == target_cls)[0]\n",
    "    label = class_to_label[target_cls]\n",
    "\n",
    "    n_cols = 3 # # of sample plot\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=n_cols, nrows=4, figsize=(25, 16))\n",
    "\n",
    "    for i in range(n_cols):\n",
    "        \n",
    "        img = Images[indices[i]]\n",
    "        # for cam\n",
    "        x = np.expand_dims(img, axis=0)\n",
    "        x = preprocess_input(copy.deepcopy(x))\n",
    "\n",
    "        # original\n",
    "        axs[0, i].imshow(np.uint8(img))\n",
    "        axs[0, i].set_title(label)\n",
    "        axs[0, i].set_xticks([])\n",
    "        axs[0, i].set_yticks([])\n",
    "        if i == 0:\n",
    "            axs[0, i].set_ylabel('Original', rotation=0, ha='right')\n",
    "\n",
    "        # Grad-CAM\n",
    "        cls_pred, cam = grad_cam(model=model, x=x, layer_name=layer_name)\n",
    "        _, _, img_grad_cam = superimpose(img, cam)\n",
    "        axs[1, i].imshow(img_grad_cam)\n",
    "        axs[1, i].set_title('pred: ' + class_to_label[cls_pred])\n",
    "        axs[1, i].set_xticks([])\n",
    "        axs[1, i].set_yticks([])\n",
    "        if i == 0:\n",
    "            axs[1, i].set_ylabel('Grad-CAM', rotation=0, ha='right')\n",
    "\n",
    "        # Grad-CAM++\n",
    "        cls_pred, cam = grad_cam_plus_plus(model=model, x=x, layer_name=layer_name)\n",
    "        _, _, img_grad_cam_plus_plus = superimpose(img, cam)\n",
    "        axs[2, i].imshow(img_grad_cam_plus_plus)\n",
    "        axs[2, i].set_title('pred: ' + class_to_label[cls_pred])\n",
    "        axs[2, i].set_xticks([])\n",
    "        axs[2, i].set_yticks([])\n",
    "        if i == 0:\n",
    "            axs[2, i].set_ylabel('Grad-CAM++', rotation=0, ha='right')\n",
    "\n",
    "        # Score-CAM\n",
    "        cls_pred, cam = score_cam(model=model, x=x, layer_name=layer_name)\n",
    "        _, _, img_score_cam = superimpose(img, cam)\n",
    "        axs[3, i].imshow(img_score_cam)\n",
    "        axs[3, i].set_title('pred: ' + class_to_label[cls_pred])\n",
    "        axs[3, i].set_xticks([])\n",
    "        axs[3, i].set_yticks([])\n",
    "        if i == 0:\n",
    "            axs[3, i].set_ylabel('Score-CAM', rotation=0, ha='right')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check_training_situation\n",
    "_compare(model=model, layer_name=model.layers[-2].name, target_cls=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.models import load_model\n",
    "import time\n",
    "\n",
    "model = load_model(\"test_resnet50.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cam shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 影像讀取\n",
    "def image_result():\n",
    "    cam2 = cv2.VideoCapture('rtsp://192.168.0.7:8554/live')\n",
    "    #cam2 = cv2.VideoCapture('rtsp://10.17.1.142:8554/live')\n",
    "\n",
    "#     cam2 = cv2.VideoCapture('http://admin:admin@10.17.1.131:8081/')\n",
    "    ticks_begin = time.time()\n",
    "    while True:\n",
    "        ret, img = cam2.read()\n",
    "        vis = img.copy()\n",
    "        medicine_img = img\n",
    "        ticks_medium = time.time()\n",
    "        if ticks_medium-ticks_begin>=3:\n",
    "            break\n",
    "        if 0xFF & cv2.waitKey(3) == 27:\n",
    "            break\n",
    "    #print(\"只給你5秒讀取:\",ticks_medium-ticks_begin)\n",
    "    cv2.imwrite('d:/7.medicine_project/dataset/testset/025866/000001.jpg', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def imageform_generate():\n",
    "    ## test資料轉換為ImageDataGenerator格式, 比照train/validation data logging\n",
    "    RImages, RClasses = get_images(dir_name='d:/7.medicine_project/dataset/testset',label_to_class=label_to_class)\n",
    "    RImages.shape, RClasses.shape\n",
    "    \n",
    "    ## real image\n",
    "    x_real = RImages\n",
    "    y_real = RClasses\n",
    "    \n",
    "    ## to one-hot\n",
    "    y_real = keras.utils.to_categorical(y_real, n_classes)\n",
    "    \n",
    "    ## to image data generator\n",
    "    datagen_real = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,) # image preprocessing function\n",
    "    \n",
    "    ## predict image result\n",
    "    x = preprocess_input(copy.deepcopy(x_real))\n",
    "    y_preds = model.predict(x).tolist()[0]\n",
    "    #print('y_preds:',y_preds)\n",
    "\n",
    "    ## transfer to the medicine name\n",
    "    class_number = y_preds.index(max(y_preds))\n",
    "    #print('class_number:',class_number)\n",
    "    labels = dict((k,v) for k,v in class_to_label.items())\n",
    "    #print('labels:',labels)\n",
    "    \n",
    "    predictions = class_to_label[int(class_number)]\n",
    "    #print('predictions:',predictions)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def detector():\n",
    "    image_result()\n",
    "    image_class = imageform_generate()\n",
    "    drugname_to_class = {\n",
    "    '025866': 'Amoxicillin',\n",
    "    '006271': 'Fucole PARAN',\n",
    "    '013382': 'Magnesium Oxide',\n",
    "    '046613': 'U-Chu Tonec',\n",
    "    '029090': 'TonFul',\n",
    "    '022105': 'Ulexin',\n",
    "    '046118': 'B.H.L',\n",
    "    '037441': 'Biperin',\n",
    "    '011701': 'Peiwetsu',\n",
    "    '006263': 'Bismuth',\n",
    "    '028452': 'Buscopan',\n",
    "    '018620': 'Undiarrhea',\n",
    "    '045267': 'U-Chuaceo',\n",
    "    '040011': 'Acemet',\n",
    "    '055232': 'KetenE.M.C.',\n",
    "    '004085': 'Alinamin-F50',\n",
    "    '027940': 'Beesix',\n",
    "    '044710': 'CetyFilm',\n",
    "    '004928': 'DailyCare',\n",
    "    '039863': 'Gincare',\n",
    "    '040699': 'Ginkgocentrate',\n",
    "    '038575': 'MabalCapsules',\n",
    "    '021882': 'Ningilon',\n",
    "    '009102': 'Propranolol',\n",
    "    '047418': 'Suride',\n",
    "    '015392': 'Transamin'\n",
    "    \n",
    "    }\n",
    "    classname = drugname_to_class.get(image_class)\n",
    "    print('辨便Bang影片判斷結果為:',image_class,classname)\n",
    "    img = cv2.imread('d:/7.medicine_project/dataset/testset/025866/000001.jpg')\n",
    "    cv2.imshow(classname, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(100000):\n",
    "    detector()\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
